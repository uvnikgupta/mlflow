{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import joblib\r\n",
    "import pandas as pd\r\n",
    "import mlflow\r\n",
    "from mlflow.tracking import MlflowClient\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "\r\n",
    "backend_uri = os.environ['MLFLOW_TRACKING_URI']\r\n",
    "artifact_uri = os.environ['MLFLOW_ARTIFACT_STORE']\r\n",
    "mlflow.set_tracking_uri(backend_uri)\r\n",
    "experiment_name = \"testing\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def delete_temp_files(files):\r\n",
    "    for f in files:\r\n",
    "        if os.path.exists(f):\r\n",
    "            os.remove(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def set_mlflow_experiment(experiment_name):\r\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\r\n",
    "    if experiment is None:\r\n",
    "        experiment_id = mlflow.create_experiment(experiment_name, artifact_location=artifact_uri)\r\n",
    "        experiment = mlflow.get_experiment(experiment_id)\r\n",
    "\r\n",
    "    mlflow.set_experiment(experiment.name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = pd.read_csv(\"../../dataset/housing.csv\")\r\n",
    "\r\n",
    "features = [\"housing_median_age\", \"total_rooms\"]\r\n",
    "target = [\"housing_median_value\"]\r\n",
    "x = data[features]\r\n",
    "y = data[features]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple sklearn pipeline logged as sklearn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "pipe = Pipeline([\r\n",
    "    (\"scale\", StandardScaler()),\r\n",
    "    (\"model\", LinearRegression())\r\n",
    "])\r\n",
    "\r\n",
    "pipe.fit(x, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('model', LinearRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "pipeline_path = \"pipe.pkl\"\r\n",
    "joblib.dump(pipe, pipeline_path)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['pipe.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "set_mlflow_experiment(experiment_name)\r\n",
    "\r\n",
    "with mlflow.start_run():\r\n",
    "        mlflow.log_param(\"pyfunc\", 0)\r\n",
    "        mlflow.sklearn.log_model(pipe, 'basic_sklearn_pipeline')\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/07/26 18:25:51 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple sklearn pipeline logged as pyfunc"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "artifacts_1 = {\r\n",
    "    \"model\": pipeline_path\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class ModelWrapper_1(mlflow.pyfunc.PythonModel):\r\n",
    "    def load_context(self, context):\r\n",
    "        self.model = joblib.load(context.artifacts[\"model\"])\r\n",
    "        return super().load_context(context)\r\n",
    "    \r\n",
    "    def predict(self, context, model_input):\r\n",
    "        return self.model.predict(model_input)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "set_mlflow_experiment(experiment_name)\r\n",
    "with mlflow.start_run():\r\n",
    "        mlflow.log_param(\"pyfunc\", 1)\r\n",
    "        mlflow.pyfunc.log_model('pyfunc_pipeline',\r\n",
    "                                python_model = ModelWrapper_1(),\r\n",
    "                                artifacts = artifacts_1)\r\n",
    "mlflow.end_run()\r\n",
    "\r\n",
    "delete_temp_files([pipeline_path])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline and model stored separately"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler())])\r\n",
    "pipe.fit(x)\r\n",
    "x_transformed = pipe.transform(x)\r\n",
    "\r\n",
    "model = LinearRegression()\r\n",
    "model.fit(x_transformed, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pipeline_path = \"pipe.pkl\"\r\n",
    "joblib.dump(pipe, pipeline_path)\r\n",
    "\r\n",
    "model_path = \"model.pkl\"\r\n",
    "joblib.dump(model, model_path)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "artifacts_2 = {\r\n",
    "    \"pipeline\": pipeline_path,\r\n",
    "    \"model\": model_path\r\n",
    "}\r\n",
    "\r\n",
    "class ModelWrapper_2(mlflow.pyfunc.PythonModel):\r\n",
    "    def load_context(self, context):\r\n",
    "        self.pipeline = joblib.load(context.artifacts[\"pipeline\"])\r\n",
    "        self.model = joblib.load(context.artifacts[\"model\"])\r\n",
    "        return super().load_context(context)\r\n",
    "    \r\n",
    "    def predict(self, context, model_input):\r\n",
    "        input_matrix = self.pipeline.transform(model_input)\r\n",
    "        return self.model.predict(input_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "set_mlflow_experiment(experiment_name)\r\n",
    "with mlflow.start_run():\r\n",
    "        mlflow.log_param(\"pyfunc\", 2)\r\n",
    "        mlflow.pyfunc.log_model('pyfunc_right_way',\r\n",
    "                                python_model = ModelWrapper_2(),\r\n",
    "                                artifacts = artifacts_2)\r\n",
    "mlflow.end_run()\r\n",
    "\r\n",
    "delete_temp_files([pipeline_path, model_path])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline and Model stored together in a folder under the current folder.\r\n",
    "## This does not work! The .pkl files have to be saved locally before logging the pyfunc model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "save_path = os.path.join(experiment_name, \"artifacts\")\r\n",
    "try:\r\n",
    "    os.makedirs(save_path)\r\n",
    "except:\r\n",
    "    pass\r\n",
    "\r\n",
    "pipeline_save_file = \"pipe.pkl\"\r\n",
    "joblib.dump(pipe, os.path.join(save_path, pipeline_save_file))\r\n",
    "\r\n",
    "model_save_file = \"model.pkl\"\r\n",
    "joblib.dump(model, os.path.join(save_path, model_save_file))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['testing\\\\artifacts\\\\model.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "artifacts_3 = {\r\n",
    "    \"pipeline\": pipeline_save_file, \r\n",
    "    \"model\": model_save_file \r\n",
    "}\r\n",
    "\r\n",
    "class ModelWrapper_3(mlflow.pyfunc.PythonModel):\r\n",
    "    def load_context(self, context):\r\n",
    "        self.pipeline = joblib.load(context.artifacts[\"pipeline\"])\r\n",
    "        self.model = joblib.load(context.artifacts[\"model\"])\r\n",
    "        return super().load_context(context)\r\n",
    "    \r\n",
    "    def predict(self, context, model_input):\r\n",
    "        input_matrix = self.pipeline.transform(model_input)\r\n",
    "        return self.model.predict(input_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "set_mlflow_experiment(experiment_name)\r\n",
    "with mlflow.start_run():\r\n",
    "        mlflow.log_param(\"pyfunc\", 3)\r\n",
    "        mlflow.pyfunc.log_model('pyfunc_stored_differently',\r\n",
    "                                python_model = ModelWrapper_3(),\r\n",
    "                                artifacts = artifacts_3,\r\n",
    "                                code_path = [save_path])\r\n",
    "mlflow.end_run()\r\n",
    "delete_temp_files([os.path.join(save_path, pipeline_save_file), \r\n",
    "                   os.path.join(save_path, model_save_file)])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pipe.pkl'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-72937f1cf897>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pyfunc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         mlflow.pyfunc.log_model('pyfunc_stored_differently',\n\u001b[0m\u001b[0;32m      5\u001b[0m                                 \u001b[0mpython_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelWrapper_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0martifacts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0martifacts_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py\u001b[0m in \u001b[0;36mlog_model\u001b[1;34m(artifact_path, loader_module, data_path, code_path, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for)\u001b[0m\n\u001b[0;32m   1205\u001b[0m                             \u001b[0mwaits\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfive\u001b[0m \u001b[0mminutes\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mSpecify\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[0mto\u001b[0m \u001b[0mskip\u001b[0m \u001b[0mwaiting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \"\"\"\n\u001b[1;32m-> 1207\u001b[1;33m     return Model.log(\n\u001b[0m\u001b[0;32m   1208\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\models\\model.py\u001b[0m in \u001b[0;36mlog\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[0mrun_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_or_start_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mmlflow_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mflavor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlflow_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlflow_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(path, loader_module, data_path, code_path, conda_env, mlflow_model, python_model, artifacts, signature, input_example, **kwargs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msecond_argument_set_specified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m         return mlflow.pyfunc.model._save_model_with_class_artifacts_params(\n\u001b[0m\u001b[0;32m   1085\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[0mpython_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpython_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\pyfunc\\model.py\u001b[0m in \u001b[0;36m_save_model_with_class_artifacts_params\u001b[1;34m(path, python_model, artifacts, conda_env, code_paths, mlflow_model)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0msaved_artifacts_dir_subpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"artifacts\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0martifact_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martifact_uri\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martifacts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                 tmp_artifact_path = _download_artifact_from_uri(\n\u001b[0m\u001b[0;32m    157\u001b[0m                     \u001b[0martifact_uri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_artifacts_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                 )\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py\u001b[0m in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mroot_uri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlunparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     )\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py\u001b[0m in \u001b[0;36mdownload_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_artifacts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;31m# NOTE: The artifact_path is expected to be in posix format.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# Posix paths work fine on windows but just in case we normalize it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\u001b[0m in \u001b[0;36mdownload_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m    183\u001b[0m             )\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdownload_artifact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_artifact_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_local_dir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdst_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\u001b[0m in \u001b[0;36mdownload_artifact\u001b[1;34m(src_artifact_path, dst_local_dir_path)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0msrc_artifact_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_artifact_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_local_dir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdst_local_dir_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             )\n\u001b[1;32m--> 130\u001b[1;33m             self._download_file(\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[0mremote_file_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_artifact_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_destination_file_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             )\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py\u001b[0m in \u001b[0;36m_download_file\u001b[1;34m(self, remote_file_path, local_path)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# Posix paths work fine on windows but just in case we normalize it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mremote_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martifact_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdelete_artifacts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\blis\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pipe.pkl'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('blis': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "ef94d82f6a94bc6da5cce44ba2c149173d1f18c778c797ebcbf6812c049dc8dd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}