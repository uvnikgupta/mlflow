FROM jupyter/pyspark-notebook:ubuntu-20.04

#RUN apt-get update \
#    && apt-get install -y --no-install-recommends git \
#    && apt-get purge -y --auto-remove \
#    && rm -rf /var/lib/apt/lists/*

RUN pip install -U --no-cache-dir dvc[s3] \
    && pip install -U --no-cache-dir mlflow \
    && pip install -U --no-cache-dir psycopg2-binary \
    && pip install -U --no-cache-dir boto3 \
    && pip install -U --no-cache-dir scikit-learn==0.24.2 \
    && pip install --no-cache-dir tensorflow==2.5.0 \
    && pip install -U --no-cache-dir joblib==0.15.1 \
    && pip install --no-cache-dir pyspark-stubs black blackcellmagic

RUN pip install -U --no-cache-dir pyspark==3.1.2

USER root
RUN apt-get update -y && apt-get install g++ -y
RUN pip install shap
USER jovyan

#RUN mkdir -p /home/jovyan
#RUN useradd jovyan && chown jovyan:jovyan /home/jovyan
#USER jovyan

ENV AWS_ACCESS_KEY_ID minioadmin
ENV AWS_SECRET_ACCESS_KEY minioadmin
ENV MLFLOW_S3_ENDPOINT_URL http://172.17.0.4:9000
ENV MLFLOW_TRACKING_URI postgresql+psycopg2://postgres:password@172.17.0.2:5432
ENV MLFLOW_ARTIFACT_STORE s3://mlruns

COPY notebooks/ /home/jovyan/work/notebooks/
COPY dataset/ /home/jovyan/work/dataset/
COPY scripts/*housing.py /home/jovyan/work/
COPY notebooks/custom_data_transformers/ /home/jovyan/work/custom_data_transformers/
USER root
RUN chown jovyan /home/jovyan/work/*
WORKDIR /home/jovyan/work
USER jovyan

ENV PORT 8000
EXPOSE ${PORT}
CMD ["/bin/sh", "-c", "git init \
                    && git config --global user.email 'you@example.com' \
                    && git config --global user.name 'Your name' \
                    && echo 'notebooks/' > .gitignore \
                    && git add .gitignore \
                    && dvc init \
                    && git commit -m 'initialize repo' \
                    && dvc remote add -d train s3://traindata \
                    && dvc remote modify train endpointurl ${MLFLOW_S3_ENDPOINT_URL} \
                    && dvc remote modify train access_key_id ${AWS_ACCESS_KEY_ID} \
                    && dvc remote modify train secret_access_key ${AWS_SECRET_ACCESS_KEY} \
                    && git commit .dvc/config -m 'configure dvc remote storage' \
                    && dvc add dataset/housing.csv \
                    && git add dataset/housing.csv.dvc dataset/.gitignore \
                    && git commit -m 'data : track' \
                    && git tag -a 'v1' -m 'raw data' \
                    && dvc push \
                    && rm -fr dataset/housing.csv \
                    && rm -fr .dvc/cache/ \
                    && dvc pull \
                    && sed -i '2,1001d' dataset/housing.csv \
                    && dvc add dataset/housing.csv \
                    && git add dataset/housing.csv.dvc \
                    && git commit -m 'data : remove first 1000 lines' \
                    && git tag -a 'v2' -m 'removed 1000 lines' \
                    && dvc push \
                    && { python tf_housing.py && python sk_housing.py && python custom_housing.py; } & \
                    jupyter-notebook --ip='*' --port=${PORT} --no-browser --NotebookApp.token='' --NotebookApp.password=''"]